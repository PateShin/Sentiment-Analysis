# -*- coding: utf-8 -*-
"""TextSentimentAmazonDF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dNmmODOmVxZcZ_NXgo5HFWSuIp5pTYzM

Data Set from https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/
"""

import tensorflow as tf
import tensorflow_datasets as tfds

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

import matplotlib.pyplot as plt
import numpy as np

import pandas as pd
import gzip
import json

def parse(path):
  g = gzip.open(path, 'r')
  for l in g:
    yield json.loads(l)

def parse(path):
  g = gzip.open(path, 'rb')
  for l in g:
    yield json.loads(l)

def getDF(path):
  i = 0
  df = {}
  for d in parse(path):
    df[i] = d
    i += 1
  return pd.DataFrame.from_dict(df, orient='index')

df = getDF('Software.json.gz')

df

new_df = df[['overall','reviewText']]
new_df

new_df.isnull().any()

clean_df = new_df.dropna(axis=0).reset_index(drop=True)

clean_df.isnull().any()

clean_df["overall"] = np.where(clean_df["overall"] <= 3, 0, 1)

clean_df

num_ex = len(clean_df)
slicing = int(0.8*num_ex)
print(slicing)

train_df = clean_df.iloc[:slicing, :]
test_df = clean_df.iloc[slicing:, :]

print(f"Train dataset's shape : {train_df.shape}")
print(f"Test dataset's shape : {test_df.shape}")

train_df

test_df

train_Y = np.array(train_df['overall'])
test_Y = np.array(test_df['overall'])

train_Y
#test_Y

train_text_X = train_df['reviewText'].values.tolist()
test_text_X = test_df['reviewText'].values.tolist()

# Change to .iloc feature

def clean_str_pandas(df, text_column):
    df[text_column] = df[text_column].str.replace(r"[^A-Za-z0-9(),!?\'\`]", " ", regex=True)
    df[text_column] = df[text_column].str.replace(r"\'s", " \'s", regex=True)
    df[text_column] = df[text_column].str.replace(r"\'ve", " \'ve", regex=True)
    df[text_column] = df[text_column].str.replace(r"n\'t", " n\'t", regex=True)
    df[text_column] = df[text_column].str.replace(r"\'re", " \'re", regex=True)
    df[text_column] = df[text_column].str.replace(r"\'d", " \'d", regex=True)
    df[text_column] = df[text_column].str.replace(r"\'ll", " \'ll", regex=True)
    df[text_column] = df[text_column].str.replace(r",", " , ", regex=True)
    df[text_column] = df[text_column].str.replace(r"!", " ! ", regex=True)
    df[text_column] = df[text_column].str.replace(r"\(", " \( ", regex=True)
    df[text_column] = df[text_column].str.replace(r"\)", " \) ", regex=True)
    df[text_column] = df[text_column].str.replace(r"\?", " \? ", regex=True)
    df[text_column] = df[text_column].str.replace(r"\s{2,}", " ", regex=True)
    df[text_column] = df[text_column].str.replace(r"\'", "", regex=True)
    df[text_column] = df[text_column].str.lower().str.strip()

    return df

train_clean = clean_str_pandas(train_df, 'reviewText')
test_clean = clean_str_pandas(test_df, 'reviewText')

train_text_X = train_clean['reviewText'].values.tolist()
test_text_X = test_clean['reviewText'].values.tolist()

print(len(train_text_X))
print(type(train_text_X))

print(train_text_X[0])
print(test_text_X[0])

# Train to list with words
train_sentences = [str(sentence).split(' ') for sentence in train_text_X]

test_sentences = [str(sentence).split(' ') for sentence in test_text_X]

for i in range(5):
    print(test_sentences[i])

for i in range(5):
    print(train_sentences[i])

less_100 = 0
for i in range(len(train_sentences)):
  if len(train_sentences[i]) < 100:
    less_100 += 1
  else:
    continue

print(less_100)
ratio = less_100 / len(train_sentences)
print(ratio)

print(train_sentences[i])

# Approx. 75% of 80% of entire data with less then 100 words

new_text = []
for i in train_sentences:
    new_text.append(i[:100])
train_sentences = new_text

new_text = []
for i in test_sentences:
    new_text.append(i[:100])
sentences = new_text

num_words=30000
tokenizer = Tokenizer(num_words)

tokenizer.fit_on_texts(train_sentences)

train_X = tokenizer.texts_to_sequences(train_sentences)

train_X = pad_sequences(train_X, padding='post')

print(train_X[:5])

test_X = tokenizer.texts_to_sequences(sentences)
test_X = pad_sequences(test_X, padding='post')

model = tf.keras.Sequential([
  tf.keras.layers.Embedding(30000, 400, input_length=100),
  tf.keras.layers.LSTM(units=50),
  tf.keras.layers.Dense(2, activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()

history = model.fit(train_X, train_Y, epochs=5, batch_size=128, validation_split=0.2)

import matplotlib.pyplot as plt
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], 'b-', label='loss')
plt.plot(history.history['val_loss'], 'r--', label='val_loss')
plt.xlabel('Epoch')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], 'g-', label='accuracy')
plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')
plt.xlabel('Epoch')
plt.ylim(0.7, 1)
plt.legend()

plt.show()



import matplotlib.pyplot as plt
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], 'b-', label='loss')
plt.plot(history.history['val_loss'], 'r--', label='val_loss')
plt.xlabel('Epoch')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], 'g-', label='accuracy')
plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')
plt.xlabel('Epoch')
plt.ylim(0.7, 1)
plt.legend()

plt.show()

model.evaluate(test_X, test_Y, verbose=1)

#testing_sentence = 'Im trying to find out the word about this product, it has acceptable quality beyond the its price'
testing_sentence = 'That was sleepy but very fun and excellent'
testing_sentence = testing_sentence.split(' ')
try_sentences = []
now_sentence = []
for word in testing_sentence:
    now_sentence.append(word)
    try_sentences.append(now_sentence[:])

test_X_sample = tokenizer.texts_to_sequences(try_sentences)
test_X_sample = pad_sequences(test_X_sample, padding='post', maxlen=100)
prediction = model.predict(test_X_sample)

inPercentage = round(prediction[-1][1] * 100, 2)
print(f'Percentage of postive is {inPercentage}%')

inPercentagePos = round(prediction[-1][1] * 100, 2)
inPercentageNeg = round(prediction[-1][0] * 100, 2)

if prediction[-1][0] < 0.5:
  print(f'Percentage of postive is {inPercentagePos}%')
else:
  print(f'Percentage of neg is {inPercentageNeg}%')